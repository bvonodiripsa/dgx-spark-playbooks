services:
  app:
    build:
      context: ../..
      dockerfile: deploy/docker/Dockerfile
    ports:
      - '3001:3000'
    environment:
      # Graph Database configurations - all available for testing
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password
      - ARANGODB_URL=http://arangodb:8529
      - ARANGODB_DB=txt2kg
      - ARANGODB_USER=root
      - ARANGODB_PASSWORD=password
      - JENA_ENDPOINT=http://jena-fuseki:3030
      - JENA_DATASET=txt2kg
      - JENA_USERNAME=${JENA_USERNAME:-admin}
      - JENA_PASSWORD=${JENA_PASSWORD:-admin}
      # Vector embeddings
      - PINECONE_HOST=entity-embeddings
      - PINECONE_PORT=5081
      - PINECONE_API_KEY=pclocal
      - PINECONE_ENVIRONMENT=local
      # NLP and ML services
      - LANGCHAIN_TRACING_V2=true
      - SENTENCE_TRANSFORMER_URL=http://sentence-transformers:80
      - MODEL_NAME=all-MiniLM-L6-v2
      # LLM configurations
      - OLLAMA_BASE_URL=http://ollama:11434/v1
      - OLLAMA_MODEL=llama3.1:8b
      - VLLM_BASE_URL=http://vllm:8001/v1
      - VLLM_MODEL=meta-llama/Llama-3.2-3B-Instruct
      # WebGPU rendering
      - REMOTE_WEBGPU_SERVICE_URL=http://txt2kg-remote-webgpu:8083
      # Node.js optimizations
      - NODE_OPTIONS=--max-http-header-size=80000
      - UV_THREADPOOL_SIZE=128
      - GRPC_SSL_CIPHER_SUITES=HIGH+ECDSA:HIGH+aRSA
      - NODE_TLS_REJECT_UNAUTHORIZED=0
    networks:
      - pinecone-net
      - default
      - txt2kg-network
    depends_on:
      neo4j:
        condition: service_healthy
      arangodb:
        condition: service_started
      jena-fuseki:
        condition: service_healthy
      entity-embeddings:
        condition: service_started
      sentence-transformers:
        condition: service_started

  # Neo4j Graph Database
  neo4j:
    image: neo4j:5.15-community
    container_name: neo4j-test
    ports:
      - '7474:7474'
      - '7687:7687'
    environment:
      - NEO4J_AUTH=neo4j/password
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      - NEO4J_dbms_security_procedures_allowlist=apoc.*
      - NEO4J_dbms_memory_heap_initial__size=512m
      - NEO4J_dbms_memory_heap_max__size=2G
      - NEO4J_dbms_memory_pagecache_size=1G
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_plugins:/plugins
    networks:
      - default
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "cypher-shell", "-u", "neo4j", "-p", "password", "RETURN 1" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ArangoDB Graph Database  
  arangodb:
    image: arangodb:latest
    container_name: arangodb-test
    ports:
      - '8529:8529'
    environment:
      - ARANGO_ROOT_PASSWORD=password
    volumes:
      - arangodb_data:/var/lib/arangodb3
      - arangodb_apps_data:/var/lib/arangodb3-apps
    networks:
      - default
    restart: unless-stopped

  # ArangoDB database initialization
  arangodb-init:
    image: arangodb:latest
    depends_on:
      arangodb:
        condition: service_started
    restart: on-failure
    entrypoint: >
      sh -c "
        echo 'Waiting for ArangoDB to start...' &&
        sleep 15 &&
        echo 'Creating txt2kg database...' &&
        arangosh --server.endpoint tcp://arangodb:8529 --server.username root --server.password password --javascript.execute-string 'try { db._createDatabase(\"txt2kg\"); console.log(\"Database txt2kg created successfully!\"); } catch(e) { if(e.message.includes(\"duplicate\")) { console.log(\"Database txt2kg already exists\"); } else { throw e; } }'
      "
    networks:
      - default

  # Apache Jena Fuseki SPARQL Database
  jena-fuseki:
    image: secoresearch/fuseki:latest
    container_name: jena-fuseki-test
    ports:
      - '3030:3030'
    environment:
      - ADMIN_PASSWORD=${JENA_PASSWORD:-admin}
      - FUSEKI_DATASET_1=txt2kg
      - FUSEKI_DATASET_2=test
      # JVM optimizations
      - JAVA_OPTIONS=-Xmx2g -Xms1g -Dfuseki.cors.enabled=true
    volumes:
      - jena_data:/fuseki/databases
      - jena_config:/fuseki/configuration
    networks:
      - default
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:3030/$/ping" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Jena Fuseki initialization
  jena-init:
    image: curlimages/curl:latest
    depends_on:
      jena-fuseki:
        condition: service_healthy
    restart: "no"
    entrypoint: >
      sh -c "
        echo 'Waiting for Jena Fuseki to be ready...' &&
        sleep 15 &&
        echo 'Creating txt2kg dataset...' &&
        curl -X POST 'http://jena-fuseki:3030/$$/datasets' \
          -H 'Content-Type: application/x-www-form-urlencoded' \
          -d 'dbName=txt2kg&dbType=tdb2' \
          --user admin:${JENA_PASSWORD:-admin} \
          --fail-with-body || echo 'Dataset creation failed or already exists' &&
        echo 'Jena Fuseki initialization completed'
      "
    networks:
      - default

  # Vector Embeddings Storage
  entity-embeddings:
    image: ghcr.io/pinecone-io/pinecone-index:latest
    container_name: entity-embeddings
    environment:
      PORT: 5081
      INDEX_TYPE: serverless
      VECTOR_TYPE: dense
      DIMENSION: 384
      METRIC: cosine
      INDEX_NAME: entity-embeddings
    ports:
      - "5081:5081"
    platform: linux/amd64
    networks:
      - pinecone-net
    restart: unless-stopped

  # Sentence Transformers Service
  sentence-transformers:
    build:
      context: ../../deploy/services/sentence-transformers
      dockerfile: Dockerfile
    container_name: sentence-transformers-test
    ports:
      - '8000:80'
    environment:
      - MODEL_NAME=all-MiniLM-L6-v2
    networks:
      - default
    restart: unless-stopped

  # Ollama LLM Service
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-test
    ports:
      - '11434:11434'
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_GPU_LAYERS=999
      - OLLAMA_GPU_MEMORY_FRACTION=0.9
      - CUDA_VISIBLE_DEVICES=0
      - OLLAMA_NUM_PARALLEL=1
    networks:
      - default
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

  # vLLM Service
  vllm:
    build:
      context: ../../deploy/services/vllm
      dockerfile: Dockerfile
    container_name: vllm-test
    ports:
      - '8001:8001'
    environment:
      - VLLM_MODEL=meta-llama/Llama-3.2-3B-Instruct
      - VLLM_TENSOR_PARALLEL_SIZE=1
      - VLLM_MAX_MODEL_LEN=4096
      - VLLM_GPU_MEMORY_UTILIZATION=0.9
      - VLLM_QUANTIZATION=fp8
      - VLLM_KV_CACHE_DTYPE=fp8
      - VLLM_PORT=8001
      - VLLM_HOST=0.0.0.0
    volumes:
      - vllm_models:/app/models
      - /tmp:/tmp
    networks:
      - default
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8001/v1/models" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

volumes:
  # Neo4j volumes
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  neo4j_plugins:
    driver: local
  # ArangoDB volumes
  arangodb_data:
    driver: local
  arangodb_apps_data:
    driver: local
  # Jena volumes
  jena_data:
    driver: local
  jena_config:
    driver: local
  # LLM volumes
  ollama_data:
    driver: local
  vllm_models:
    driver: local

networks:
  pinecone-net:
    name: pinecone
  default:
    driver: bridge
  txt2kg-network:
    driver: bridge
