#!/usr/bin/env python3
"""
Remote WebGPU Clustering Service

Provides GPU-accelerated graph clustering for remote browsers that lack WebGPU support.
Offers two modes:
1. Hybrid: GPU clustering on server, CPU rendering on client
2. WebRTC Streaming: Full GPU rendering streamed to client browser

This service acts as a bridge for browsers without WebGPU support to still benefit
from NVIDIA GPU acceleration for large graph clustering and visualization.
"""

import os
import json
import uuid
import asyncio
import logging
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Union
from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, BackgroundTasks
from fastapi.responses import HTMLResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import time
import threading
from concurrent.futures import ThreadPoolExecutor
import base64
from io import BytesIO

# GPU-accelerated imports
try:
    import cudf
    import cugraph
    import cupy as cp
    from cuml import UMAP
    HAS_RAPIDS = True
    print("✓ RAPIDS cuGraph/cuDF/cuML available for remote WebGPU clustering")
except ImportError:
    HAS_RAPIDS = False
    print("⚠ RAPIDS not available, falling back to CPU for remote clustering")
    import networkx as nx

# WebRTC streaming imports
try:
    import cv2
    import PIL.Image as PILImage
    HAS_OPENCV = True
    print("✓ OpenCV available for WebRTC streaming")
except ImportError:
    HAS_OPENCV = False
    print("⚠ OpenCV not available, WebRTC streaming disabled")

# WebGL rendering imports for server-side visualization
try:
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')  # Use non-interactive backend
    import plotly.graph_objects as go
    import plotly.io as pio
    pio.renderers.default = "json"
    HAS_PLOTTING = True
    print("✓ Plotting libraries available for server-side rendering")
except ImportError:
    HAS_PLOTTING = False
    print("⚠ Plotting libraries not available")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GraphData(BaseModel):
    nodes: List[Dict[str, Any]]
    links: List[Dict[str, Any]]

class ClusteringMode(str):
    HYBRID = "hybrid"  # GPU clustering, CPU rendering on client
    WEBRTC_STREAM = "webrtc_stream"  # Full GPU rendering streamed to client

class RemoteClusteringRequest(BaseModel):
    graph_data: GraphData
    mode: str = ClusteringMode.HYBRID
    cluster_dimensions: List[int] = [32, 18, 24]
    force_simulation: bool = True
    max_iterations: int = 100
    webrtc_options: Optional[Dict[str, Any]] = None

class ClusteringResult(BaseModel):
    clustered_nodes: List[Dict[str, Any]]
    cluster_info: Dict[str, Any]
    processing_time: float
    mode: str
    session_id: Optional[str] = None

class WebRTCSession(BaseModel):
    session_id: str
    client_id: str
    created_at: datetime
    last_frame_time: datetime
    is_active: bool = True

class RemoteWebGPUClusteringEngine:
    """
    Server-side implementation of WebGPU clustering using RAPIDS cuGraph
    Mimics the WebGPU clustering behavior but runs on server GPU
    """
    
    def __init__(self, cluster_dimensions: Tuple[int, int, int] = (32, 18, 24)):
        self.cluster_dimensions = cluster_dimensions
        self.cluster_count = cluster_dimensions[0] * cluster_dimensions[1] * cluster_dimensions[2]
        self.has_gpu = HAS_RAPIDS
        logger.info(f"Remote WebGPU clustering engine initialized with {self.cluster_count} clusters")
        
    def cluster_nodes_gpu(self, nodes: List[Dict[str, Any]]) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """
        Perform GPU-accelerated node clustering using cuGraph
        Mimics the WebGPU shader clustering algorithm
        """
        if not self.has_gpu:
            return self._cluster_nodes_cpu(nodes)
            
        try:
            start_time = time.time()
            
            # Convert nodes to cuDF DataFrame
            node_data = []
            for i, node in enumerate(nodes):
                node_data.append({
                    'node_id': i,
                    'x': float(node.get('x', 0)),
                    'y': float(node.get('y', 0)), 
                    'z': float(node.get('z', 0)),
                    'size': float(node.get('val', 1))
                })
            
            df = cudf.DataFrame(node_data)
            
            # Apply clustering algorithm similar to WebGPU shader
            # Normalize positions to [0, 1] range
            df['norm_x'] = (df['x'] / 100.0 + 0.5).clip(0.0, 0.999)
            df['norm_y'] = (df['y'] / 100.0 + 0.5).clip(0.0, 0.999)
            df['norm_z'] = (df['z'] / 100.0 + 0.5).clip(0.001, 0.999)
            
            # Apply logarithmic scaling to Z dimension (like WebGPU shader)
            df['log_z'] = cp.log(df['norm_z']) / cp.log(0.999)
            df['log_z'] = df['log_z'].clip(0.0, 0.999)
            
            # Calculate cluster indices
            df['cluster_x'] = (df['norm_x'] * self.cluster_dimensions[0]).astype('int32')
            df['cluster_y'] = (df['norm_y'] * self.cluster_dimensions[1]).astype('int32')  
            df['cluster_z'] = (df['log_z'] * self.cluster_dimensions[2]).astype('int32')
            
            # Ensure cluster indices are within bounds
            df['cluster_x'] = df['cluster_x'].clip(0, self.cluster_dimensions[0] - 1)
            df['cluster_y'] = df['cluster_y'].clip(0, self.cluster_dimensions[1] - 1)
            df['cluster_z'] = df['cluster_z'].clip(0, self.cluster_dimensions[2] - 1)
            
            # Calculate final cluster index
            df['cluster_index'] = (df['cluster_x'] + 
                                 df['cluster_y'] * self.cluster_dimensions[0] + 
                                 df['cluster_z'] * self.cluster_dimensions[0] * self.cluster_dimensions[1])
            
            # Convert back to list format
            clustered_nodes = []
            for i, node in enumerate(nodes):
                cluster_idx = int(df.iloc[i]['cluster_index'])
                clustered_node = {
                    **node,
                    'cluster_index': cluster_idx,
                    'node_index': i
                }
                clustered_nodes.append(clustered_node)
            
            # Generate cluster statistics
            cluster_stats = df.groupby('cluster_index').agg({
                'node_id': 'count',
                'x': ['min', 'max', 'mean'],
                'y': ['min', 'max', 'mean'], 
                'z': ['min', 'max', 'mean']
            }).to_pandas()
            
            processing_time = time.time() - start_time
            
            cluster_info = {
                'total_clusters': self.cluster_count,
                'used_clusters': len(cluster_stats),
                'cluster_dimensions': self.cluster_dimensions,
                'processing_time': processing_time,
                'gpu_accelerated': True,
                'cluster_stats': cluster_stats.to_dict() if len(cluster_stats) > 0 else {}
            }
            
            logger.info(f"GPU clustering completed in {processing_time:.3f}s for {len(nodes)} nodes")
            return clustered_nodes, cluster_info
            
        except Exception as e:
            logger.error(f"GPU clustering failed: {e}")
            return self._cluster_nodes_cpu(nodes)
    
    def _cluster_nodes_cpu(self, nodes: List[Dict[str, Any]]) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """CPU fallback clustering implementation"""
        start_time = time.time()
        
        clustered_nodes = []
        for i, node in enumerate(nodes):
            # Apply same clustering logic as GPU version
            x = float(node.get('x', 0))
            y = float(node.get('y', 0))
            z = float(node.get('z', 0))
            
            # Normalize positions
            norm_x = max(0.0, min(0.999, x / 100.0 + 0.5))
            norm_y = max(0.0, min(0.999, y / 100.0 + 0.5))
            norm_z = max(0.001, min(0.999, z / 100.0 + 0.5))
            
            # Apply logarithmic scaling to Z
            log_z = max(0.0, min(0.999, np.log(norm_z) / np.log(0.999)))
            
            # Calculate cluster indices
            cluster_x = min(self.cluster_dimensions[0] - 1, int(norm_x * self.cluster_dimensions[0]))
            cluster_y = min(self.cluster_dimensions[1] - 1, int(norm_y * self.cluster_dimensions[1]))
            cluster_z = min(self.cluster_dimensions[2] - 1, int(log_z * self.cluster_dimensions[2]))
            
            cluster_index = (cluster_x + 
                           cluster_y * self.cluster_dimensions[0] + 
                           cluster_z * self.cluster_dimensions[0] * self.cluster_dimensions[1])
            
            clustered_node = {
                **node,
                'cluster_index': cluster_index,
                'node_index': i
            }
            clustered_nodes.append(clustered_node)
        
        processing_time = time.time() - start_time
        
        cluster_info = {
            'total_clusters': self.cluster_count,
            'cluster_dimensions': self.cluster_dimensions,
            'processing_time': processing_time,
            'gpu_accelerated': False
        }
        
        logger.info(f"CPU clustering completed in {processing_time:.3f}s for {len(nodes)} nodes")
        return clustered_nodes, cluster_info

class ForceSimulationEngine:
    """
    GPU-accelerated force simulation for graph layout
    Provides server-side alternative to WebGPU force computation
    """
    
    def __init__(self):
        self.has_gpu = HAS_RAPIDS
        
    def simulate_forces(self, nodes: List[Dict[str, Any]], links: List[Dict[str, Any]], 
                       max_iterations: int = 100) -> List[Dict[str, Any]]:
        """Run force-directed layout simulation"""
        
        if not self.has_gpu:
            return self._simulate_forces_cpu(nodes, links, max_iterations)
            
        try:
            return self._simulate_forces_gpu(nodes, links, max_iterations)
        except Exception as e:
            logger.error(f"GPU force simulation failed: {e}")
            return self._simulate_forces_cpu(nodes, links, max_iterations)
    
    def _simulate_forces_gpu(self, nodes: List[Dict[str, Any]], links: List[Dict[str, Any]], 
                            max_iterations: int) -> List[Dict[str, Any]]:
        """GPU-accelerated force simulation using cuGraph"""
        
        # Create graph structure
        edge_list = []
        for link in links:
            source_id = str(link.get('source', ''))
            target_id = str(link.get('target', ''))
            edge_list.append([source_id, target_id])
        
        if not edge_list:
            return nodes  # No links, return original positions
            
        # Convert to cuDF
        edges_df = cudf.DataFrame(edge_list, columns=['source', 'target'])
        
        # Create cuGraph
        G = cugraph.Graph()
        G.from_cudf_edgelist(edges_df, source='source', destination='target')
        
        # Use Force Atlas 2 layout (GPU-accelerated)
        try:
            pos_df = cugraph.force_atlas2(G, max_iter=max_iterations)
            
            # Update node positions
            pos_dict = dict(zip(pos_df['vertex'].to_pandas(), 
                              zip(pos_df['x'].to_pandas(), pos_df['y'].to_pandas())))
            
            updated_nodes = []
            for node in nodes:
                node_id = str(node.get('id', ''))
                if node_id in pos_dict:
                    x, y = pos_dict[node_id]
                    updated_node = {**node, 'x': float(x), 'y': float(y)}
                else:
                    updated_node = node
                updated_nodes.append(updated_node)
                
            return updated_nodes
            
        except Exception as e:
            logger.warning(f"Force Atlas 2 failed, using NetworkX: {e}")
            return self._simulate_forces_cpu(nodes, links, max_iterations)
    
    def _simulate_forces_cpu(self, nodes: List[Dict[str, Any]], links: List[Dict[str, Any]], 
                            max_iterations: int) -> List[Dict[str, Any]]:
        """CPU fallback force simulation using NetworkX"""
        
        import networkx as nx
        
        G = nx.Graph()
        
        # Add nodes
        for node in nodes:
            G.add_node(str(node.get('id', '')), **node)
            
        # Add edges
        for link in links:
            source = str(link.get('source', ''))
            target = str(link.get('target', ''))
            G.add_edge(source, target)
        
        # Compute spring layout
        pos = nx.spring_layout(G, iterations=max_iterations, k=1.0)
        
        # Update node positions
        updated_nodes = []
        for node in nodes:
            node_id = str(node.get('id', ''))
            if node_id in pos:
                x, y = pos[node_id]
                updated_node = {**node, 'x': float(x * 100), 'y': float(y * 100)}
            else:
                updated_node = node
            updated_nodes.append(updated_node)
            
        return updated_nodes

class WebRTCStreamingEngine:
    """
    WebRTC streaming engine for real-time graph visualization streaming
    Renders graphs server-side and streams frames to remote browsers
    """
    
    def __init__(self):
        self.has_rendering = HAS_PLOTTING and HAS_OPENCV
        self.active_sessions: Dict[str, WebRTCSession] = {}
        self.frame_buffer: Dict[str, bytes] = {}
        
    def create_session(self, client_id: str) -> str:
        """Create new WebRTC streaming session"""
        session_id = str(uuid.uuid4())
        session = WebRTCSession(
            session_id=session_id,
            client_id=client_id,
            created_at=datetime.now(),
            last_frame_time=datetime.now()
        )
        self.active_sessions[session_id] = session
        logger.info(f"Created WebRTC session {session_id} for client {client_id}")
        return session_id
    
    def render_graph_frame(self, session_id: str, nodes: List[Dict[str, Any]], 
                          links: List[Dict[str, Any]]) -> bool:
        """Render graph to frame buffer for streaming"""
        
        if not self.has_rendering:
            logger.error("Rendering libraries not available")
            return False
            
        if session_id not in self.active_sessions:
            logger.error(f"Session {session_id} not found")
            return False
            
        try:
            # Create 3D plotly visualization
            node_x = [node.get('x', 0) for node in nodes]
            node_y = [node.get('y', 0) for node in nodes] 
            node_z = [node.get('z', 0) for node in nodes]
            node_text = [node.get('name', f"Node {i}") for i, node in enumerate(nodes)]
            node_colors = [node.get('cluster_index', 0) for node in nodes]
            
            # Create node trace
            node_trace = go.Scatter3d(
                x=node_x, y=node_y, z=node_z,
                mode='markers',
                marker=dict(
                    size=8,
                    color=node_colors,
                    colorscale='Viridis',
                    showscale=True
                ),
                text=node_text,
                hovertemplate='%{text}<br>(%{x:.1f}, %{y:.1f}, %{z:.1f})<extra></extra>',
                name='Nodes'
            )
            
            # Create edge traces
            edge_traces = []
            for link in links:
                source_idx = None
                target_idx = None
                
                # Find source and target indices
                for i, node in enumerate(nodes):
                    if str(node.get('id', '')) == str(link.get('source', '')):
                        source_idx = i
                    if str(node.get('id', '')) == str(link.get('target', '')):
                        target_idx = i
                        
                if source_idx is not None and target_idx is not None:
                    edge_trace = go.Scatter3d(
                        x=[node_x[source_idx], node_x[target_idx], None],
                        y=[node_y[source_idx], node_y[target_idx], None],
                        z=[node_z[source_idx], node_z[target_idx], None],
                        mode='lines',
                        line=dict(color='gray', width=2),
                        showlegend=False,
                        hoverinfo='none'
                    )
                    edge_traces.append(edge_trace)
            
            # Create figure
            fig = go.Figure(data=[node_trace] + edge_traces)
            fig.update_layout(
                title='GPU-Clustered Knowledge Graph',
                scene=dict(
                    xaxis_title='X',
                    yaxis_title='Y', 
                    zaxis_title='Z',
                    bgcolor='rgb(10, 10, 10)'
                ),
                showlegend=False,
                paper_bgcolor='rgb(10, 10, 10)',
                plot_bgcolor='rgb(10, 10, 10)',
                font=dict(color='white')
            )
            
            # Convert to image
            img_bytes = pio.to_image(fig, format='png', width=1200, height=800, engine='kaleido')
            
            # Store frame in buffer
            self.frame_buffer[session_id] = img_bytes
            self.active_sessions[session_id].last_frame_time = datetime.now()
            
            return True
            
        except Exception as e:
            logger.error(f"Frame rendering failed for session {session_id}: {e}")
            return False
    
    def get_frame(self, session_id: str) -> Optional[bytes]:
        """Get latest frame for streaming"""
        return self.frame_buffer.get(session_id)
    
    def cleanup_session(self, session_id: str):
        """Clean up streaming session"""
        if session_id in self.active_sessions:
            del self.active_sessions[session_id]
        if session_id in self.frame_buffer:
            del self.frame_buffer[session_id]
        logger.info(f"Cleaned up WebRTC session {session_id}")

class RemoteWebGPUService:
    """Main service class combining all remote WebGPU capabilities"""
    
    def __init__(self):
        self.clustering_engine = RemoteWebGPUClusteringEngine()
        self.force_engine = ForceSimulationEngine()
        self.webrtc_engine = WebRTCStreamingEngine()
        self.active_connections: List[WebSocket] = []
        self.executor = ThreadPoolExecutor(max_workers=4)
        
    async def process_clustering_request(self, request: RemoteClusteringRequest) -> ClusteringResult:
        """Process remote clustering request"""
        
        start_time = time.time()
        
        try:
            nodes = request.graph_data.nodes
            links = request.graph_data.links
            
            # Apply force simulation if requested
            if request.force_simulation:
                logger.info("Running force simulation...")
                nodes = self.force_engine.simulate_forces(nodes, links, request.max_iterations)
            
            # Perform clustering
            logger.info(f"Clustering {len(nodes)} nodes in {request.mode} mode...")
            clustered_nodes, cluster_info = self.clustering_engine.cluster_nodes_gpu(nodes)
            
            processing_time = time.time() - start_time
            
            result = ClusteringResult(
                clustered_nodes=clustered_nodes,
                cluster_info=cluster_info,
                processing_time=processing_time,
                mode=request.mode
            )
            
            # Handle WebRTC streaming mode
            if request.mode == ClusteringMode.WEBRTC_STREAM:
                session_id = self.webrtc_engine.create_session("remote_client")
                success = self.webrtc_engine.render_graph_frame(session_id, clustered_nodes, links)
                if success:
                    result.session_id = session_id
                    
            return result
            
        except Exception as e:
            logger.error(f"Clustering request failed: {e}")
            raise HTTPException(status_code=500, detail=str(e))
    
    async def broadcast_update(self, data: Dict[str, Any]):
        """Broadcast updates to connected WebSocket clients"""
        if not self.active_connections:
            return
            
        disconnected = []
        for connection in self.active_connections:
            try:
                await connection.send_json(data)
            except Exception:
                disconnected.append(connection)
                
        for connection in disconnected:
            self.active_connections.remove(connection)

# FastAPI app setup
app = FastAPI(
    title="Remote WebGPU Clustering Service",
    description="GPU-accelerated graph clustering for remote browsers",
    version="1.0.0"
)

# Enable CORS for cross-origin requests
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize service
service = RemoteWebGPUService()

@app.post("/api/cluster", response_model=ClusteringResult)
async def cluster_graph(request: RemoteClusteringRequest):
    """Process graph clustering request"""
    result = await service.process_clustering_request(request)
    
    # Broadcast to WebSocket clients
    await service.broadcast_update({
        "type": "clustering_complete",
        "data": result.dict()
    })
    
    return result

@app.get("/api/capabilities")
async def get_capabilities():
    """Get service capabilities"""
    return {
        "modes": {
            "hybrid": {
                "available": True,
                "description": "GPU clustering on server, CPU rendering on client"
            },
            "webrtc_stream": {
                "available": service.webrtc_engine.has_rendering,
                "description": "Full GPU rendering streamed to client browser"
            }
        },
        "gpu_acceleration": {
            "rapids_available": HAS_RAPIDS,
            "opencv_available": HAS_OPENCV,
            "plotting_available": HAS_PLOTTING
        },
        "cluster_dimensions": service.clustering_engine.cluster_dimensions,
        "max_cluster_count": service.clustering_engine.cluster_count
    }

@app.get("/api/stream/{session_id}")
async def stream_frame(session_id: str):
    """Stream rendered frame for WebRTC session"""
    frame_data = service.webrtc_engine.get_frame(session_id)
    if not frame_data:
        raise HTTPException(status_code=404, detail="Frame not found")
        
    return StreamingResponse(
        BytesIO(frame_data),
        media_type="image/png",
        headers={"Cache-Control": "no-cache"}
    )

@app.delete("/api/stream/{session_id}")
async def cleanup_stream(session_id: str):
    """Clean up WebRTC streaming session"""
    service.webrtc_engine.cleanup_session(session_id)
    return {"status": "cleaned up"}

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket endpoint for real-time updates"""
    await websocket.accept()
    service.active_connections.append(websocket)
    
    try:
        while True:
            # Keep connection alive
            await websocket.receive_text()
    except WebSocketDisconnect:
        service.active_connections.remove(websocket)

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "gpu_available": HAS_RAPIDS,
        "webrtc_available": service.webrtc_engine.has_rendering,
        "active_sessions": len(service.webrtc_engine.active_sessions),
        "active_connections": len(service.active_connections)
    }

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8083))
    logger.info(f"Starting Remote WebGPU Clustering Service on port {port}")
    logger.info(f"GPU acceleration: {'✓' if HAS_RAPIDS else '✗'}")
    logger.info(f"WebRTC streaming: {'✓' if service.webrtc_engine.has_rendering else '✗'}")
    
    uvicorn.run(
        "remote_webgpu_clustering_service:app",
        host="0.0.0.0",
        port=port,
        log_level="info",
        reload=False
    )
